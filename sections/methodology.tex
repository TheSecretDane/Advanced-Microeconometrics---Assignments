\section{Methodology} \label{sec:methodology}

We start by taking logs of \eqref{eq:CD} to linearize it,
\begin{align*}
    \ln Y_{it} &= \ln A_{it} + \beta_K \ln K_{it} + \beta_L \ln L_{it} \quad \Longrightarrow
    y_{it} = \beta_K k_{it} + \beta_L l_{it} + v_{it}, \quad v_{it} = \ln A_{it}
\end{align*}
where $y_{it} = \ln Y_{it}$ and so on. Suppose that $\ln A_{it}$ can be decomposed into a time-invariant firm-specific effect, $c_i$ and add an idiosyncratic error, $u_{it}$, such that the composite error is $\ln A_{it}=v_{it} = c_i + u_{it}$. Our model can then be written as:
\begin{align*}
    y_{it} &= \beta_K k_{it} + \beta_L l_{it}+c_i + u_{it}
\end{align*}
We write the model on compact form by stacking the regressors in the vector $\bm{x}_{it} = (k_{it}, l_{it})$ and the parameters in the vector $\bm{\beta} = (\beta_K, \beta_L)'$.
\begin{align} \label{equationline}
    y_{it} = c_i + \bm{x}_{it} \bm{\beta} + u_{it}, \quad t=1,2,\ldots,8, \quad i=1,2,\ldots,441
\end{align}

All distributional results are based on fixed $T$ large $N$ asymptotic approximations, synonymous with Micro panel econometric theory in which the cross-sectional dimension is large relative to the time dimension. We consider three estimators: Pooled OLS, Fixed Effects and First-Differences.  

\subsubsection*{Pooled OLS}
The pooled OLS (POLS) estimator performs OLS on the entire panel, treating each $(i,t)$ observation as i.i.d. In POLS, identification of $\pmb{\beta}$ requires  $\mathbb{E}[\pmb{x}_{it}'v_{it}]=\mathbb{E}[\pmb{x}_{it}'\alpha_{i}]+\mathbb{E}[\pmb{x}_{it}'u_{it}]=0$.
%In the context of the data, both the time-varying and time-invariant part of TFP must then be assumed uncorrelated with both the log of capital and employment.
An example of $\mathbb{E}[\pmb{x}_{it}'v_{it}]\neq0$ is that if there is some firm-specific effect, say the TFP level from our Cobb-Douglas production function on the log of sales, it will correlate with the log of capital and/or employment, i.e. $\mathbb{E}[\pmb{x}_{it}'c_{i}]\neq0$. Therefore we consider the class of Fixed Effects Methods to alleviate the omitted variable problem in POLS.

\subsubsection*{Fixed Effects and First Differences}
The Fixed Effects (FE) and First Differences (FD) estimators doesn't suffer from same identification issues as the POLS estimator. We show this for FE by performing a within-transformation on \eqref{equationline} and generalize for FD. For each firm $i$, we subtract the average (over $T$) dependent variable  on the LHS and the average (over $T$) regressors on the RHS. In this way, the time-invariant TFP $c_i$ cancels out. Define the demeaned variable as $ \ddot{y}_{it}, \pmb{\ddot{x}}_{it}, \ddot{u}_{it}$.
\begin{align*}
    y_{it}-\bar{y}_{i} &=(\pmb{x}_{it}-\bar{\pmb{x}}_{i}) \pmb{\beta}+(c_i-c_i)+(u_{it} - \bar{u}_{i}) \\
    \ddot{y}_{it} &=  \ddot{\pmb{x}}_{it} \pmb{\beta}+\ddot{u}_{it}
\end{align*}
and analogous for FD with $\Delta y_{it}=\Delta \pmb{x}_{it}\pmb{\beta}+\Delta u_{it}$ where $\Delta \pmb{x}_{it}=\pmb{x}_{it}-\pmb{x}_{it-1}$ and so on. Correct identification i assumed, for unbiased estimation of $\pmb{\beta}$. For simplicity, we stack the data over the time-dimension such that $\ddot{\pmb{y}}_{i}$ and $\ddot{\pmb{u}}_{i}$ are $T \times 1$ vectors and $\pmb{\ddot{X}}$ is a $T\times K$ matrix. Using the model equation, premultiplying $\pmb{\ddot{X}}_{i}$, taking expectations and rearranging, we get the following.
$$ \Rightarrow  \pmb{\beta} = (\mathbb{E}[\pmb{\ddot{X}}_{i}'\pmb{\ddot{X}}_{i}])^{-1} \left(  \mathbb{E}[\pmb{\ddot{X}}_{i}'\pmb{\ddot{y}}_{i}]-\mathbb{E}[\pmb{\ddot{X}}_{i}' \pmb{\ddot{u}}_{i}]\right)$$
, i.e. we see that $\pmb{\beta}$ is identified as $\pmb{\beta} = (\mathbb{E}[\pmb{\ddot{X}}_{i}'\pmb{\ddot{X}}_{i}])^{-1} \mathbb{E}[\pmb{\ddot{X}}_{i}'\pmb{y}_{i}]$ if we assume the following:
\begin{enumerate}
    \item[\textbf{FE.1, FD.1}] \underline{Strict exogenity} $\mathbb{E}[u_{it}\vert \pmb{x}_{i1},\pmb{x}_{i2}\dots,\pmb{x}_{iT},c_i]=0\Rightarrow \mathbb{E}[\pmb{\ddot{X}}_{i}' \pmb{\ddot{u}}_{i}]=0$ \\
    The time-varying error term must be exogenous to both log of capital and employment, reflecting no dependence of production shocks on log of capital or employment, neither contemporaneous, leaded or lagged. For FE, this implies $\mathbb{E}[ \ddot{u}_{it} \vert\pmb{\ddot{x}}_{it}]=0$, while it implies $\mathbb{E}[\Delta \pmb{\ddot{x}}_{it} \Delta u_{it}]=0$
    \item[\textbf{FE.2, FD.2}] \underline{ (full) rank condition}: $\text{rank}(\mathbb{E}[\pmb{\ddot{X}}_{i}'\pmb{\ddot{X}}_{i}])=K$ for FE and $\text{rank}(\mathbb{E}[\Delta\pmb{X}_{i}' \Delta\pmb{X}_{i}])=K$ \\
    Log of capital and employment can't be linearly dependent.
\end{enumerate}

With FE, estimation of $\pmb{\beta}$ under FE.1 and FE.2 using the analogy principle gives the following.
\begin{equation} \label{EstimationEq}
    \pmb{\hat{\beta}}_{FE}= \left( \frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i} } \right) ^{-1}\frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{y}}_{i} }
\end{equation}
, where we emphasize that the former expectation for the population is over the firms $i$ (and not $t$).

%% With $\pmb{\ddot{X}}'\pmb{\ddot{X}}$, we obtain a $(K \times K)$ matrix, which, with a $(K \times 1)$ vector from $\pmb{\ddot{X'}}_{i} \pmb{\ddot{y}}_{i}$ results in a $(K \times 1)$ vector $\pmb{\beta}$.

\subsubsection*{Consistency of Fixed Effects estimator}
We evaluate the consistency of the FE-estimator $\pmb{\hat{\beta}}_{FE}$ by inserting $\pmb{\ddot{y}}_i$ in \eqref{EstimationEq}, and generalize for the FD-estimator.
\begin{align}
    \Rightarrow \pmb{\hat{\beta}}_{FE} &= \left( \frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i} } \right) ^{-1} \left(\frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i}}\pmb{\ddot{X}}_{i} \pmb{\beta}+\pmb{\ddot{X'}}_{i}\pmb{\ddot{u}}_i \right) \nonumber = \pmb{\beta} +\left( \frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i} } \right) ^{-1} \left( \frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X}}_i' \pmb{\ddot{u}}_i} \right) \label{FE-estimator}
\end{align}
Under FE.1 and FE.2, we can apply a Law of Large Numbers (LLN) and Slutsky's theorem (using that the inverse of a matrix is continuous mapping) which shows us that $\pmb{\hat{\beta}}_{FE}$ is consistent for $\beta$,

%%we can then we apply a Law of Large Numbers (LLN) such that $p\text{-lim}\left(\frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i} } \right)=\mathbb{E}[\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i}]$ and $p\text{-lim}\left(\frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{u}}_{i} } \right)=\mathbb{E}[\pmb{\ddot{X'}}_{i} \pmb{\ddot{u}}_{i}]=0$. Then we use Slutskys theorem: $p\text{-lim}\left( \left(\frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i} } \right)^{-1}\right)=(\mathbb{E}[\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i}])^{-1}$, which is allowed since the inverse matrix is defined, due to the rank assumption, and the inverse operator is a continuous function.
$$p\text{-lim}(\pmb{\hat{\beta}}_{FE})=\pmb{\beta} + \left( \mathbb{E}[\ddot{\pmb{X'}}_i \ddot{\pmb{X}}_i] \right)^{-1}\mathbb{E}[\ddot{\pmb{X'}}_i \ddot{\pmb{u}}_i]=\pmb{\beta} + \left( \mathbb{E}[\ddot{\pmb{X'}}_i \ddot{\pmb{X}}_i] \right)^{-1}*\pmb{0} =\pmb{\beta}$$

\subsubsection*{Asymptotic normality of Fixed Effects estimator}
Rearranging \eqref{EstimationEq} and using $\mathbb{E}[\sqrt{N}(\pmb{\hat{\beta}}_{FE}-\pmb{\beta})]=\pmb{0}$ under FE.1 and FE.2, we see that the sum of products of regressors and time-varying errors converge according to the Central Limit Theorem (CLT). The product rule then implies that the product of the two matrices converges (only) in distribution. Again, we generalize for the FD-estimator. 
\begin{align} 
    \sqrt{N}(\pmb{\hat{\beta}}_{FE}-\pmb{\beta}) &=  \left( \frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i} } \right) ^{-1} \left( \frac{1}{\sqrt{N}} \sum_{i=1}^N {\pmb{\ddot{X}}_i' \pmb{\ddot{u}}_i} \right) \notag
    \xrightarrow{d} \text{N} \left(\pmb{0},
(\mathbb{E}[\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i}])^{-1} \mathbb{E}[\pmb{\ddot{X}}_i' \pmb{\ddot{u}}_i\pmb{\ddot{u}}_i'\pmb{\ddot{X}}_i] (\mathbb{E}[\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i}])^{-1} \right)
\end{align}

%Earlier, we saw that FE.1 and FE.2 combined with LLN and Slutsky's theorem implied that asymptotically $\mathbb{E}[\sqrt{N}(\pmb{\hat{\beta}}_{FE}-\pmb{\beta})]=\pmb{0}$. This means that the sum of real-valued i.i.d. r.v.s converges accordingly to the Central Limit Theorem such that $\left( \frac{1}{\sqrt{N}} \sum_{i=1}^N {\pmb{\ddot{X}}_i' \pmb{\ddot{u}}_i} \right)\rightarrow _d \text{N}(\pmb{0},\mathbb{E}[\pmb{\ddot{X}}_i' \pmb{\ddot{u}}_i(\pmb{\ddot{X}}_i' \pmb{\ddot{u}}_i)'])=^d \text{N}(\pmb{0},\mathbb{E}[\pmb{\ddot{X}}_i' \pmb{\ddot{u}}_i\pmb{\ddot{u}}_i'\pmb{\ddot{X}}_i])$.

%%Since we have convergence in probability $p\text{-lim}\left( \left(\frac{1}{N} \sum_{i=1}^N {\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i} } \right)^{-1}\right)=(\mathbb{E}[\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i}])^{-1}$ for the first term and convergence in distribution for the second term, %%
%The product rule implies that the expression for $\sqrt{N}(\pmb{\hat{\beta}}_{FE}-\pmb{\beta})$ converges only in the distributional sense such that:
%$$\Rightarrow \sqrt{N}(\pmb{\hat{\beta}}_{FE}-\pmb{\beta}) \sim \text{N} \left(\pmb{0},
%(\mathbb{E}[\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i}])^{-1} \mathbb{E}[\pmb{\ddot{X}}_i' \pmb{\ddot{u}}_i\pmb{\ddot{u}}_i'\pmb{\ddot{X}}_i] (\mathbb{E}[\pmb{\ddot{X'}}_{i} \pmb{\ddot{X}}_{i}])^{-1} \right)$$

\input{sections/meth/efficiency.tex}

\subsubsection*{Wald-test}

% --- [Comment out section] --- %

%only include (assumptions, variance estimators, etc) that we actually use in the assignment

%If we use normal standard errors, we require stronger assumptions where under assumption FE.3 the FE estimator is asymptotically efficient $\rightarrow$ we can use normal standard errors. If we relax assumption FE.3, or simply reject the null-hypothesis from a serial-correlation test, like a placebo test with an AR(1) model, (\textit{see section for serial correlation for this specific test}) we have to use robust standard errors. 

%\begin{equation*}
%    W_{robust}= (\begin{bmatrix}1&1 \end{bmatrix} 
%    \begin{bmatrix} 0.154620 \\ 0.694226 \end{bmatrix}-1)[\begin{bmatrix}1&1 \end{bmatrix}
%    \begin{bmatrix}
%        0.001735 & -0.000727 \\ 
%        -0.000727 & 0.0008968
%    \end{bmatrix} \begin{bmatrix}1&1 \end{bmatrix}-1]\approx 19.402912
%\end{equation*}

%$H_0:\textbf{R}\boldsymbol{\beta}=\hat{\textbf{r}}$, where we estimate $\hat{\textbf{r}}$ instead of stating what it must be. From the null-hypothesis from the Wald-test we simply state $\textbf{r}=1$, but now we try to estimate $\hat{\textbf{r}}$, and the simple t-test setup looks like the classical t-test framework $H_0: \hat{\beta}=\beta\Rightarrow$
%\begin{align*}
%    H_0:\hat{\textbf{r}}&=\textbf{r}\Leftrightarrow %\hat{\textbf{r}}=1\Leftrightarrow  \\
%     \textbf{R}\boldsymbol{\hat{\beta}}&=1\Leftrightarrow %\hat{\beta}_K+\hat{\beta_L}=1
%\end{align*}
%Insert the estimates into the framework into the t-statistic:
%\begin{equation*}
%    t=\frac{\hat{\beta}_K+\hat{\beta}_L-1}{se(\hat{\textbf{r}})}
%    \Leftrightarrow \frac{0.154620+0.694226-1}{0.001178}\approx-4.404874
%\end{equation*}
%And t squared $t^2=(-4.404873)^2\approx19.402906\approx W_{robust}=19.402912$.

% ---------------------- %

We utilise the Wald-test to test for CRS, where the null-hypothesis is $H_0: \mathbf{R}\boldsymbol{\beta}=\mathbf{r}$. Under weak regularity conditions, that \textbf{FE.1-2} holds and we are using cluster robust standard errors, the Wald statistic can be written as:
\begin{equation*}
    W:=(\mathbf{R}{\boldsymbol{\hat\beta}}-\mathbf{r})'
    [\mathbf{R}\widehat{\text{Avar}({\boldsymbol{\hat{\beta}}}_{FE})}\mathbf{R}']^{-1}
    (\mathbf{R} \boldsymbol{\hat{\beta}}-\mathbf{r})
\end{equation*}
The null- and alternative-hypothesis for testing CRS is:
\begin{align*}
  H_0 & : \mathbf{R}\boldsymbol{\beta}=\mathbf{r} \Leftrightarrow
\begin{bmatrix} 1&1 \end{bmatrix} \begin{bmatrix} \beta_K \\ \beta_L \end{bmatrix} =1
\Leftrightarrow \beta_K+\beta_L=1  \\
H_A & : \beta_K+\beta_L \neq 1
\end{align*}

If the assumptions for the Wald-test holds we also see the squared $t$-statistic, $t^2$, is equivalent to the Wald-statistic: $t^2=(\frac{\textbf{R}\bm{\hat\beta}-1}{se(\bm{\hat\beta})})^2$ where  $\text{se}(\bm{\hat\beta})=\sqrt{\text{Avar}(\hat\beta_K)+\text{Avar}(\hat\beta_L)+2\text{ACov}({\hat\beta_K,\hat\beta_L}})$. For a joint test this pattern follows a $F$-distribution, not a squared $t$-distribution. This is important because in the strict exogeneity test for the FE and FD models it also tests for joint significance in their leaded terms, where we test for two linear restrictions.

\subsubsection*{Serial correlation test}
We utilise an autoregressive process with one lag (AR(1)) to test for serial correlation in the error termby using an auxilliary regression:
\begin{equation*}
    \hat{\ddot{u}}_{it}=\rho \hat{\ddot{u}}_{it-1}+\varepsilon_{it}
\end{equation*}
If $\hat{\ddot{u}}_{it-1}$ has a significant impact on $\hat{\ddot{u}}_{it}$ it warrants at minimal using cluster robust standard errors. While time-demeaned errors are by structure serially correlated, $\text{corr}(\hat{\ddot{u}}_{it}, \hat{\ddot{u}}_{it}) = -1/(T-1), \forall s \neq t$, under FE.3, it dies out under asymptotic properties when $T\rightarrow \infty$ for the FE model. This is \textit{not} for the case for the FD model, since $\text{Corr}(\Delta u_{it},\Delta u_{it-1})=-0.5$ if FE.3 holds (\cite[Chapter~10.6.3]{wooldridgeEconometricAnalysisCross2010}). 

%we in both cases have to use cluster robust errors that accounts for arbitrary serial correlation.  If there is arbitrary serial correlation, the t-statistic is not valid and since $\ddot{u}_{it},\ddot{u}_{it-1}$ is correlated (\textit{tends to 0 as T grows, so asymptotic properties are still exactly the same as always...)}. So using time-demeaned errors, we test for serial correlation in these errors by making the test robust to arbitrary serial correlation. The t-statistic will be valid, and if it still shows significance, it does indicate a problem. If this is the case we have to use robust standard errors in our model when estimating $\beta_K,\beta_K$, to be able to conduct valid tests.

\subsubsection*{Strict exogeneity test}

To test for strict exogeneity we test whether any (is it any, or...?) $\bm{x_{is}}$ is correlated with $\bm{u}_{it}$ for $s \neq t$. This is most easily done by testing the significance of parameter estimates on leaded explanatory variables, $\bm{x}_{it+1}$, that is estimate, 
\begin{align*}
    y_{it} = \bm{x}_{it} \bm{\beta} + \bm{w}_{it+1} \bm{\delta} + c_i + u_{it}
\end{align*} 
using FE, where $\bm{w}_{it+1} \subseteq \bm{x}_{it+1}$. Under strict exogeneity $\bm{\delta} = 0$, which is done by a regular t-test. Similarly for the FD model we use $\Delta y_{it} = \Delta \bm{x}_{it} \bm{\beta} + \bm{w}_{it} \bm{\gamma} + \Delta u_{it}$, with $\bm{w}_{it} \subseteq \bm{x}_{it}$, following \cite[Chapter~10]{wooldridgeEconometricAnalysisCross2010}.

%\subsubsection*{Homoskedasticity}
%No
